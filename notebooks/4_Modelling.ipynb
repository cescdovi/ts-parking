{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado de Series Temporales de Aparcamientos usando RNNs y optimización con Optuna\n",
    "En este notebook se abordará un problema de predicción de series temporales utilizando datos de disponibilidad de parkings.\n",
    "\n",
    "Flujo de trabajo:\n",
    "1. Agrupación de los datos por id de aparcamiento (idAparcamiento), para tratar cada parking como una serie temporal independiente.\n",
    "2. División del conjunto de datos en tres subconjuntos: entrenamiento (train), validación (val) y prueba (test).\n",
    "3. Entrenamiento de modelos de redes neuronales recurrentes simples (vanilla):\n",
    " - Vanilla RNN\n",
    " - Vanilla GRU\n",
    " - Vanilla LSTM\n",
    "4. Ajuste de hiperparámetros utilizando Optuna para encontrar la configuración óptima en cada tipo de modelo.\n",
    "5. Comparación de los resultados de rendimiento entre los distintos modelos utilizando métricas apropiadas.\n",
    "\n",
    "El objetivo final es evaluar qué arquitectura ofrece mejores resultados para este tipo de datos y tarea de predicción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.regression import MeanAbsoluteError, MeanSquaredError, MeanAbsolutePercentageError, R2Score\n",
    "\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idAparcamiento</th>\n",
       "      <th>PlazasTotales</th>\n",
       "      <th>PlazasDisponibles</th>\n",
       "      <th>PorcPlazasDisponibles</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-03 10:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>372.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.129032</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03 11:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>372.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03 12:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>372.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.741935</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03 13:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>372.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>31.989247</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-03 14:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>372.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 03:00:00</th>\n",
       "      <td>78</td>\n",
       "      <td>464.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>76.508621</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 04:00:00</th>\n",
       "      <td>78</td>\n",
       "      <td>464.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>76.508621</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 05:00:00</th>\n",
       "      <td>78</td>\n",
       "      <td>464.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>76.724138</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 06:00:00</th>\n",
       "      <td>78</td>\n",
       "      <td>464.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>76.293103</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-05 07:00:00</th>\n",
       "      <td>78</td>\n",
       "      <td>464.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>71.551724</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149395 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     idAparcamiento  PlazasTotales  PlazasDisponibles  \\\n",
       "timestamp                                                               \n",
       "2023-02-03 10:00:00               6          372.0               60.0   \n",
       "2023-02-03 11:00:00               6          372.0               48.0   \n",
       "2023-02-03 12:00:00               6          372.0               66.0   \n",
       "2023-02-03 13:00:00               6          372.0              119.0   \n",
       "2023-02-03 14:00:00               6          372.0              155.0   \n",
       "...                             ...            ...                ...   \n",
       "2025-03-05 03:00:00              78          464.0              355.0   \n",
       "2025-03-05 04:00:00              78          464.0              355.0   \n",
       "2025-03-05 05:00:00              78          464.0              356.0   \n",
       "2025-03-05 06:00:00              78          464.0              354.0   \n",
       "2025-03-05 07:00:00              78          464.0              332.0   \n",
       "\n",
       "                     PorcPlazasDisponibles  year  month  day  weekday  \n",
       "timestamp                                                              \n",
       "2023-02-03 10:00:00              16.129032  2023      2    3        4  \n",
       "2023-02-03 11:00:00              12.903226  2023      2    3        4  \n",
       "2023-02-03 12:00:00              17.741935  2023      2    3        4  \n",
       "2023-02-03 13:00:00              31.989247  2023      2    3        4  \n",
       "2023-02-03 14:00:00              41.666667  2023      2    3        4  \n",
       "...                                    ...   ...    ...  ...      ...  \n",
       "2025-03-05 03:00:00              76.508621  2025      3    5        2  \n",
       "2025-03-05 04:00:00              76.508621  2025      3    5        2  \n",
       "2025-03-05 05:00:00              76.724138  2025      3    5        2  \n",
       "2025-03-05 06:00:00              76.293103  2025      3    5        2  \n",
       "2025-03-05 07:00:00              71.551724  2025      3    5        2  \n",
       "\n",
       "[149395 rows x 8 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/data_processed.csv\")\n",
    "\n",
    "#convertir a indice\n",
    "df.set_index(\"timestamp\", inplace= True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. División del conjunto de datos\n",
    "\n",
    "Realizamos la división del conjunto de datos, agrupando por `idAparcamiento`. \n",
    "La idea es que el conjunto de **test sea común** para todos los aparcamientos, correspondiente al **último 10% del rango temporal total** del dataset. \n",
    "\n",
    "El resto de los datos disponibles para cada parking se dividen en:\n",
    "\n",
    "- **Entrenamiento (train)**: el primer 85% de los datos previos al test.\n",
    "- **Validación (val)**: el último 15% de los datos previos al test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# 1. Calcular el rango temporal global\n",
    "fecha_min_global = df.index.min()\n",
    "fecha_max_global = df.index.max()\n",
    "rango_total = fecha_max_global - fecha_min_global\n",
    "\n",
    "# 2. Calcular el inicio del conjunto de test (último 10% del rango)\n",
    "test_ratio = 0.10\n",
    "test_duration = timedelta(seconds=rango_total.total_seconds() * test_ratio)\n",
    "test_start = fecha_max_global - test_duration\n",
    "\n",
    "# 3. Diccionarios para almacenar los splits\n",
    "train_dict = {}\n",
    "val_dict = {}\n",
    "test_dict = {}\n",
    "\n",
    "val_ratio = 0.1  # del conjunto anterior al test\n",
    "\n",
    "# 4. División por parking\n",
    "for parking_id, group in df.groupby(\"idAparcamiento\"):\n",
    "    group = group.sort_index()\n",
    "    \n",
    "    # Split basado en el corte global\n",
    "    test_set = group[group.index >= test_start]\n",
    "    remaining = group[group.index < test_start]\n",
    "\n",
    "    # Dividir en train y val\n",
    "    val_size = int(len(remaining) * val_ratio)\n",
    "    val_set = remaining.iloc[-val_size:]\n",
    "    train_set = remaining.iloc[:-val_size]\n",
    "    \n",
    "    # Guardar resultados\n",
    "    train_dict[parking_id] = train_set\n",
    "    val_dict[parking_id] = val_set\n",
    "    test_dict[parking_id] = test_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definir `Dataset` de pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, input_window, output_window, feature_cols, target_col):\n",
    "        \"\"\"\n",
    "        data: DataFrame que contiene los datos de la serie temporal\n",
    "        input_window: nº de pasos de tiempo en la secuencia de entrada\n",
    "        output_window: nº de pasos de tiempo a predecir\n",
    "        feature_cols: lista de nombres de columnas que se usan como característcas\n",
    "        target_col: nombre de la variable a predecir\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.input_window = input_window\n",
    "        self.output_window = output_window\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_cols = target_col\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Función que devuele el nº de datos del Dataset\n",
    "        \"\"\"\n",
    "        return len(self.data) - self.input_window - self.output_window + 1 #\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Función que devuelve un dato a partir de un índice\n",
    "        \"\"\"\n",
    "        X = self.data[idx: idx + self.input_window][self.feature_cols].values\n",
    "        Y = self.data[idx + self.input_window: idx + self.input_window + self.output_window][self.target_cols].values\n",
    "        \n",
    "        X_tensor = torch.tensor(X, dtype= torch.float32)\n",
    "        Y_tensor = torch.tensor(Y, dtype= torch.float32)\n",
    "\n",
    "        return X_tensor, Y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['PorcPlazasDisponibles']  \n",
    "target_col = 'PorcPlazasDisponibles'     \n",
    "input_window = 24         # Número de pasos de tiempo en la secuencia de entrada\n",
    "output_window = 1         # Número de pasos de tiempo a predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que tenemos una serie temporal por parking, construimos un diccionario, donde las claves son los identificadores de parkings y los valores son Daatasets de tipo `torch.utils.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = {\n",
    "    pid: TimeSeriesDataset(df, input_window, output_window, feature_cols, target_col=target_col)\n",
    "    for pid, df in train_dict.items()\n",
    "}\n",
    "val_datasets = {\n",
    "    pid: TimeSeriesDataset(df, input_window, output_window, feature_cols, target_col=target_col)\n",
    "    for pid, df in val_dict.items()\n",
    "}\n",
    "test_datasets = {\n",
    "    pid: TimeSeriesDataset(df, input_window, output_window, feature_cols, target_col=target_col)\n",
    "    for pid, df in test_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id parking:  6\n",
      "longitud:  13908\n",
      "id parking:  7\n",
      "longitud:  13908\n",
      "id parking:  8\n",
      "longitud:  22507\n",
      "id parking:  13\n",
      "longitud:  13908\n",
      "id parking:  34\n",
      "longitud:  9310\n",
      "id parking:  75\n",
      "longitud:  22505\n",
      "id parking:  77\n",
      "longitud:  10735\n",
      "id parking:  78\n",
      "longitud:  7454\n"
     ]
    }
   ],
   "source": [
    "for pid, df in train_datasets.items():\n",
    "    print(\"id parking: \", pid)\n",
    "    print(\"longitud: \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Crear `DataLoaders` a partir de `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear los `DataLoader`, seguimos el mismo criterio, es decir, crear un diccionario de DataLoaders, en el que cada iteración nos devuelve un batch de datos para cada parking.\n",
    "- Cada batch de datos debe tener dimensión: `(batch_size, window_size, n_features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloaders = {\n",
    "    pid: DataLoader(ts_dataset, batch_size = 32, shuffle = True) #(batch_size, window_size, n_features)\n",
    "    for pid, ts_dataset in train_datasets.items()\n",
    "}\n",
    "\n",
    "val_dataloaders = {\n",
    "    pid: DataLoader(ts_dataset, batch_size = 32, shuffle = True) #(batch_size, window_size, n_features)\n",
    "    for pid, ts_dataset in val_datasets.items()\n",
    "}\n",
    "\n",
    "test_dataloaders = {\n",
    "    pid: DataLoader(ts_dataset, batch_size = 64) #(batch_size, window_size, n_features)\n",
    "    for pid, ts_dataset in test_datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id parking 6\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n",
      "id parking 7\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n",
      "id parking 8\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n",
      "id parking 13\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n",
      "id parking 34\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n",
      "id parking 75\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n",
      "id parking 77\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n",
      "id parking 78\n",
      "Dimensión del primer batch de datos: torch.Size([32, 24, 1])\n",
      "Dimensión del primer batch de etiquetas:  torch.Size([32, 1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pid, dloader in train_dataloaders.items():\n",
    "    print(\"id parking\", pid)\n",
    "    for batch in dloader:\n",
    "        print(\"Dimensión del primer batch de datos:\", batch[0].shape)\n",
    "        print(\"Dimensión del primer batch de etiquetas: \", batch[1].shape)\n",
    "        break\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Definir Modelos (`RNN`,`GRU`,`LSTM`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Clase que implementa una RNN vanilla: 1 capa, 1 neurona por capa oculta\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rnn = nn.RNN(input_size = self.input_size,\n",
    "                          hidden_size = self.hidden_size,\n",
    "                          num_layers = self.num_layers,\n",
    "                          batch_first = True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, x, h0 = None):\n",
    "        \"\"\" \n",
    "        \n",
    "        \"\"\"\n",
    "        batch_size_ = x.size(0)\n",
    "        #si no se pasa el primer estado oculto, lo inicializamos con 0\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size_, self.hidden_size).to(x.device)\n",
    "        \n",
    "        #all_hidden_states (output) --> todos los estados ocultos (batch_size, seq_length, hidden_size)\n",
    "        #last_hidden_state (h_n) --> ultimo estado oculto (num_layers, batch_size, hidden_size)\n",
    "        all_hidden_states, last_hidden_state = self.rnn(x, h0)\n",
    "\n",
    "        last_hidde_state_of_last_layer = last_hidden_state[-1]\n",
    "        \n",
    "        #si no pasamos por una capa densa, el modelo no hace la prediccion\n",
    "        pred = self.fc(last_hidde_state_of_last_layer)  # (batch_size, output_size)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que no hay inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "model = VanillaRNN(input_size=1, hidden_size=64, output_size=1, num_layers=1)\n",
    "x = torch.randn(32, 24, 1)  # (batch_size, sequence_length, num_features)\n",
    "y  = model(x)\n",
    "print(y.shape)  # → (32, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VanillaLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        batch_size_ = x.size(0)\n",
    "        #si no se pasa el primer h0 o c0, lo inicializamos con 0\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size_, self.hidden_size).to(x.device)\n",
    "        if c0 is None:\n",
    "            c0 = torch.zeros(self.num_layers, batch_size_, self.hidden_size).to(x.device)\n",
    "\n",
    "        all_hidden_states, (last_hidden_state, last_cell_memory) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Usar el último estado oculto de la última capa\n",
    "        pred = self.fc(last_hidden_state[-1])  # Shape: (batch_size, output_size)\n",
    "\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que no hay inconsistencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "model = VanillaLSTM(input_size=1, hidden_size=64, output_size=1, num_layers=1)\n",
    "x = torch.randn(32, 24, 1)  # (batch_size, sequence_length, num_features)\n",
    "y  = model(x)\n",
    "print(y.shape)  #(32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.gru = nn.GRU(input_size = self.input_size,\n",
    "                          hidden_size = self.hidden_size,\n",
    "                          num_layers = self.num_layers,\n",
    "                          batch_first= True)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, x, h0=None):\n",
    "        \n",
    "        batch_size_ = x.size(0)\n",
    "        \n",
    "        ##si no se pasa el primer h0, lo inicializamos con 0\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, batch_size_, self.hidden_size).to(x.device)\n",
    "        \n",
    "        #all_hidden_states (output) --> todos los estados ocultos (batch_size, seq_length, hidden_size)\n",
    "        #last_hidden_state (h_n) --> ultimo estado oculto (num_layers, batch_size, hidden_size)\n",
    "        all_hidden_states, last_hidden_state = self.gru(x, h0)\n",
    "\n",
    "        last_hidde_state_of_last_layer = last_hidden_state[-1]\n",
    "        \n",
    "        #si no pasamos por una capa densa, el modelo no hace la prediccion\n",
    "        pred = self.fc(last_hidde_state_of_last_layer)  # (batch_size, output_size)\n",
    "\n",
    "        return pred  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "model = VanillaGRU(input_size=1, hidden_size=64, output_size=1, num_layers=1)\n",
    "x = torch.randn(32, 24, 1)  # (batch_size, sequence_length, num_features)\n",
    "y  = model(x)\n",
    "print(y.shape)  #(32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Definir métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricCollection({\n",
    "    \"MAE\": MeanAbsoluteError(),\n",
    "    \"MSE\": MeanSquaredError(),\n",
    "    \"RMSE\": MeanSquaredError(squared = False),\n",
    "    \"MAPE\": MeanAbsolutePercentageError()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Instanciar modelos, optimizador, función de coste y learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id parking 6\n",
      "Dimensión del primer batch de datos: (32, 24, 1)\n",
      "Dimensión del primer batch de etiquetas: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "for pid, dloader in train_dataloaders.items():\n",
    "    print(\"id parking\", pid)\n",
    "    batch = next(iter(dloader))\n",
    "    INPUT_SIZE = tuple(batch[0].shape)\n",
    "    OUTPUT_SIZE = tuple(batch[1].shape)\n",
    "    print(\"Dimensión del primer batch de datos:\", INPUT_SIZE)\n",
    "    print(\"Dimensión del primer batch de etiquetas:\", OUTPUT_SIZE)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got tuple\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vanilla_rnn = \u001b[43mVanillaRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mINPUT_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m vanilla_lstm = VanillaLSTM(input_size = INPUT_SIZE, hidden_size = \u001b[32m32\u001b[39m, output_size = OUTPUT_SIZE, num_layers=\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m vanilla_gru = VanillaGRU(input_size = INPUT_SIZE, hidden_size = \u001b[32m32\u001b[39m, output_size = OUTPUT_SIZE, num_layers=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[121]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mVanillaRNN.__init__\u001b[39m\u001b[34m(self, input_size, hidden_size, output_size, num_layers)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.output_size = output_size\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.num_layers = num_layers\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mself\u001b[39m.rnn = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.fc = nn.Linear(\u001b[38;5;28mself\u001b[39m.hidden_size, \u001b[38;5;28mself\u001b[39m.output_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ts-parkings/TS-PARKINGS_VENV/lib64/python3.11/site-packages/torch/nn/modules/rnn.py:636\u001b[39m, in \u001b[36mRNN.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    634\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown nonlinearity \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.nonlinearity\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Select from \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtanh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    635\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ts-parkings/TS-PARKINGS_VENV/lib64/python3.11/site-packages/torch/nn/modules/rnn.py:166\u001b[39m, in \u001b[36mRNNBase.__init__\u001b[39m\u001b[34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional, proj_size, device, dtype)\u001b[39m\n\u001b[32m    160\u001b[39m real_hidden_size = proj_size \u001b[38;5;28;01mif\u001b[39;00m proj_size > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m hidden_size\n\u001b[32m    161\u001b[39m layer_input_size = (\n\u001b[32m    162\u001b[39m     input_size \u001b[38;5;28;01mif\u001b[39;00m layer == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m real_hidden_size * num_directions\n\u001b[32m    163\u001b[39m )\n\u001b[32m    165\u001b[39m w_ih = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_input_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m )\n\u001b[32m    168\u001b[39m w_hh = Parameter(\n\u001b[32m    169\u001b[39m     torch.empty((gate_size, real_hidden_size), **factory_kwargs)\n\u001b[32m    170\u001b[39m )\n\u001b[32m    171\u001b[39m b_ih = Parameter(torch.empty(gate_size, **factory_kwargs))\n",
      "\u001b[31mTypeError\u001b[39m: empty(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got tuple\""
     ]
    }
   ],
   "source": [
    "vanilla_rnn = VanillaRNN(input_size = INPUT_SIZE, hidden_size = 32, output_size = OUTPUT_SIZE, num_layers=1)\n",
    "vanilla_lstm = VanillaLSTM(input_size = INPUT_SIZE, hidden_size = 32, output_size = OUTPUT_SIZE, num_layers=1)\n",
    "vanilla_gru = VanillaGRU(input_size = INPUT_SIZE, hidden_size = 32, output_size = OUTPUT_SIZE, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Crear callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Definir bucle de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Definir bucle de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Optimizació óptima de hiperparámetros con `Optuna`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Predicciones sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Exportación de checkpoints y logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TS-PARKINGS_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
